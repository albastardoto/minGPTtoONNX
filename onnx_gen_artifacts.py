import onnx
import numpy as np
from onnxruntime.training import artifacts
import onnxruntime.training.onnxblock as onnxblock
from torch import Tensor, tensor

model = onnx.load("test.onnx.pb")
onnx.checker.check_model(model)
inferred_model = onnx.shape_inference.infer_shapes(model)

all_names_prev = [
    "transformer.wte.weight",
    "transformer.wpe.weight",
    "transformer.h.0.ln_1.weight",
    "transformer.h.0.ln_1.bias",
    "transformer.h.0.attn.c_attn.bias",
    "transformer.h.0.attn.c_proj.bias",
    "transformer.h.0.ln_2.weight",
    "transformer.h.0.ln_2.bias",
    "transformer.h.0.mlp.c_fc.bias",
    "transformer.h.0.mlp.c_proj.bias",
    "transformer.h.1.ln_1.weight",
    "transformer.h.1.ln_1.bias",
    "transformer.h.1.attn.c_attn.bias",
    "transformer.h.1.attn.c_proj.bias",
    "transformer.h.1.ln_2.weight",
    "transformer.h.1.ln_2.bias",
    "transformer.h.1.mlp.c_fc.bias",
    "transformer.h.1.mlp.c_proj.bias",
    "transformer.h.2.ln_1.weight",
    "transformer.h.2.ln_1.bias",
    "transformer.h.2.attn.c_attn.bias",
    "transformer.h.2.attn.c_proj.bias",
    "transformer.h.2.ln_2.weight",
    "transformer.h.2.ln_2.bias",
    "transformer.h.2.mlp.c_fc.bias",
    "transformer.h.2.mlp.c_proj.bias",
    "transformer.h.3.ln_1.weight",
    "transformer.h.3.ln_1.bias",
    "transformer.h.3.attn.c_attn.bias",
    "transformer.h.3.attn.c_proj.bias",
    "transformer.h.3.ln_2.weight",
    "transformer.h.3.ln_2.bias",
    "transformer.h.3.mlp.c_fc.bias",
    "transformer.h.3.mlp.c_proj.bias",
    "transformer.h.4.ln_1.weight",
    "transformer.h.4.ln_1.bias",
    "transformer.h.4.attn.c_attn.bias",
    "transformer.h.4.attn.c_proj.bias",
    "transformer.h.4.ln_2.weight",
    "transformer.h.4.ln_2.bias",
    "transformer.h.4.mlp.c_fc.bias",
    "transformer.h.4.mlp.c_proj.bias",
    "transformer.h.5.ln_1.weight",
    "transformer.h.5.ln_1.bias",
    "transformer.h.5.attn.c_attn.bias",
    "transformer.h.5.attn.c_proj.bias",
    "transformer.h.5.ln_2.weight",
    "transformer.h.5.ln_2.bias",
    "transformer.h.5.mlp.c_fc.bias",
    "transformer.h.5.mlp.c_proj.bias",
    "transformer.h.6.ln_1.weight",
    "transformer.h.6.ln_1.bias",
    "transformer.h.6.attn.c_attn.bias",
    "transformer.h.6.attn.c_proj.bias",
    "transformer.h.6.ln_2.weight",
    "transformer.h.6.ln_2.bias",
    "transformer.h.6.mlp.c_fc.bias",
    "transformer.h.6.mlp.c_proj.bias",
    "transformer.h.7.ln_1.weight",
    "transformer.h.7.ln_1.bias",
    "transformer.h.7.attn.c_attn.bias",
    "transformer.h.7.attn.c_proj.bias",
    "transformer.h.7.ln_2.weight",
    "transformer.h.7.ln_2.bias",
    "transformer.h.7.mlp.c_fc.bias",
    "transformer.h.7.mlp.c_proj.bias",
    "transformer.h.8.ln_1.weight",
    "transformer.h.8.ln_1.bias",
    "transformer.h.8.attn.c_attn.bias",
    "transformer.h.8.attn.c_proj.bias",
    "transformer.h.8.ln_2.weight",
    "transformer.h.8.ln_2.bias",
    "transformer.h.8.mlp.c_fc.bias",
    "transformer.h.8.mlp.c_proj.bias",
    "transformer.h.9.ln_1.weight",
    "transformer.h.9.ln_1.bias",
    "transformer.h.9.attn.c_attn.bias",
    "transformer.h.9.attn.c_proj.bias",
    "transformer.h.9.ln_2.weight",
    "transformer.h.9.ln_2.bias",
    "transformer.h.9.mlp.c_fc.bias",
    "transformer.h.9.mlp.c_proj.bias",
    "transformer.h.10.ln_1.weight",
    "transformer.h.10.ln_1.bias",
    "transformer.h.10.attn.c_attn.bias",
    "transformer.h.10.attn.c_proj.bias",
    "transformer.h.10.ln_2.weight",
    "transformer.h.10.ln_2.bias",
    "transformer.h.10.mlp.c_fc.bias",
    "transformer.h.10.mlp.c_proj.bias",
    "transformer.h.11.ln_1.weight",
    "transformer.h.11.ln_1.bias",
    "transformer.h.11.attn.c_attn.bias",
    "transformer.h.11.attn.c_proj.bias",
    "transformer.h.11.ln_2.weight",
    "transformer.h.11.ln_2.bias",
    "transformer.h.11.mlp.c_fc.bias",
    "transformer.h.11.mlp.c_proj.bias",
    "transformer.ln_f.weight",
    "transformer.ln_f.bias",
    "onnx::MatMul_2077",
    "onnx::MatMul_2091",
    "onnx::MatMul_2092",
    "onnx::MatMul_2093",
    "onnx::MatMul_2094",
    "onnx::MatMul_2108",
    "onnx::MatMul_2109",
    "onnx::MatMul_2110",
    "onnx::MatMul_2111",
    "onnx::MatMul_2125",
    "onnx::MatMul_2126",
    "onnx::MatMul_2127",
    "onnx::MatMul_2128",
    "onnx::MatMul_2142",
    "onnx::MatMul_2143",
    "onnx::MatMul_2144",
    "onnx::MatMul_2145",
    "onnx::MatMul_2159",
    "onnx::MatMul_2160",
    "onnx::MatMul_2161",
    "onnx::MatMul_2162",
    "onnx::MatMul_2176",
    "onnx::MatMul_2177",
    "onnx::MatMul_2178",
    "onnx::MatMul_2179",
    "onnx::MatMul_2193",
    "onnx::MatMul_2194",
    "onnx::MatMul_2195",
    "onnx::MatMul_2196",
    "onnx::MatMul_2210",
    "onnx::MatMul_2211",
    "onnx::MatMul_2212",
    "onnx::MatMul_2213",
    "onnx::MatMul_2227",
    "onnx::MatMul_2228",
    "onnx::MatMul_2229",
    "onnx::MatMul_2230",
    "onnx::MatMul_2244",
    "onnx::MatMul_2245",
    "onnx::MatMul_2246",
    "onnx::MatMul_2247",
    "onnx::MatMul_2261",
    "onnx::MatMul_2262",
    "onnx::MatMul_2263",
    "onnx::MatMul_2264",
    "onnx::MatMul_2278",
    "onnx::MatMul_2279",
    "onnx::MatMul_2280",
    "onnx::MatMul_2281",
]
requires_grad = [
    "transformer.h.0.mlp.c_fc.weight",
    "transformer.h.11.attn.c_proj.weight",
    "transformer.h.0.attn.c_proj.weight",
    "transformer.h.8.attn.c_attn.weight",
    "transformer.h.5.mlp.c_proj.weight",
    "transformer.h.2.attn.c_attn.weight",
    "transformer.h.9.attn.c_proj.weight",
    "lm_head.weight",
    "transformer.h.7.mlp.c_fc.weight",
    "transformer.h.7.attn.c_attn.weight",
    "transformer.h.10.attn.c_attn.weight",
    "transformer.h.4.attn.c_attn.weight",
    "transformer.h.7.mlp.c_proj.weight",
    "transformer.h.5.mlp.c_fc.weight",
    "transformer.h.8.mlp.c_fc.weight",
    "transformer.h.10.mlp.c_proj.weight",
    "transformer.h.4.mlp.c_fc.weight",
    "transformer.h.8.attn.c_proj.weight",
    "transformer.h.3.mlp.c_proj.weight",
    "transformer.h.3.mlp.c_fc.weight",
    "transformer.h.3.attn.c_attn.weight",
    "transformer.h.0.mlp.c_proj.weight",
    "transformer.h.7.attn.c_proj.weight",
    "transformer.h.10.mlp.c_fc.weight",
    "transformer.h.9.mlp.c_fc.weight",
    "transformer.h.11.mlp.c_fc.weight",
    "transformer.h.8.mlp.c_proj.weight",
    "transformer.h.3.attn.c_proj.weight",
    "transformer.h.6.attn.c_attn.weight",
    "transformer.h.0.attn.c_attn.weight",
    "transformer.h.6.mlp.c_proj.weight",
    "transformer.h.11.mlp.c_proj.weight",
    "transformer.h.6.mlp.c_fc.weight",
    "transformer.h.2.mlp.c_fc.weight",
    "transformer.h.2.mlp.c_proj.weight",
    "transformer.h.9.attn.c_attn.weight",
    "transformer.h.1.mlp.c_proj.weight",
    "transformer.h.4.mlp.c_proj.weight",
    "transformer.h.11.attn.c_attn.weight",
    "transformer.h.1.attn.c_proj.weight",
    "transformer.h.5.attn.c_attn.weight",
    "transformer.h.2.attn.c_proj.weight",
    "transformer.h.1.attn.c_attn.weight",
    "transformer.h.6.attn.c_proj.weight",
    "transformer.h.4.attn.c_proj.weight",
    "transformer.h.5.attn.c_proj.weight",
    "transformer.h.9.mlp.c_proj.weight",
    "transformer.h.1.mlp.c_fc.weight",
    "transformer.h.10.attn.c_proj.weight",
]
all_names = [param.name for param in model.graph.initializer]
frozen_params = [param for param in all_names if param not in requires_grad]
no_decay = [
    "transformer.h.9.ln_2.bias",
    "transformer.h.10.ln_2.bias",
    "transformer.h.11.mlp.c_fc.bias",
    "transformer.h.7.attn.c_attn.bias",
    "transformer.h.4.mlp.c_proj.bias",
    "transformer.h.6.mlp.c_proj.bias",
    "transformer.h.7.ln_1.bias",
    "transformer.h.7.attn.c_proj.bias",
    "transformer.h.11.attn.c_attn.bias",
    "transformer.h.0.ln_1.weight",
    "transformer.h.3.attn.c_attn.bias",
    "transformer.h.11.ln_2.weight",
    "transformer.h.9.ln_1.bias",
    "transformer.h.4.mlp.c_fc.bias",
    "transformer.h.5.ln_2.bias",
    "transformer.h.11.ln_1.bias",
    "transformer.h.11.ln_1.weight",
    "transformer.h.0.attn.c_attn.bias",
    "transformer.h.10.mlp.c_fc.bias",
    "transformer.h.10.mlp.c_proj.bias",
    "transformer.h.1.mlp.c_fc.bias",
    "transformer.h.1.ln_1.bias",
    "transformer.ln_f.bias",
    "transformer.h.6.ln_1.bias",
    "transformer.h.9.ln_1.weight",
    "transformer.h.2.ln_1.bias",
    "transformer.h.7.ln_1.weight",
    "transformer.h.8.ln_2.bias",
    "transformer.h.6.mlp.c_fc.bias",
    "transformer.h.7.mlp.c_proj.bias",
    "transformer.h.10.ln_2.weight",
    "transformer.h.10.ln_1.weight",
    "transformer.h.6.ln_1.weight",
    "transformer.h.3.ln_2.bias",
    "transformer.h.2.ln_2.weight",
    "transformer.h.8.ln_1.bias",
    "transformer.h.4.ln_2.bias",
    "transformer.h.4.ln_2.weight",
    "transformer.h.5.attn.c_proj.bias",
    "transformer.h.6.attn.c_attn.bias",
    "transformer.h.8.attn.c_attn.bias",
    "transformer.h.0.mlp.c_proj.bias",
    "transformer.h.9.mlp.c_proj.bias",
    "transformer.h.10.attn.c_proj.bias",
    "transformer.h.4.attn.c_attn.bias",
    "transformer.h.9.attn.c_proj.bias",
    "transformer.h.6.attn.c_proj.bias",
    "transformer.h.5.ln_1.weight",
    "transformer.h.2.mlp.c_fc.bias",
    "transformer.h.0.attn.c_proj.bias",
    "transformer.h.6.ln_2.bias",
    "transformer.h.8.ln_2.weight",
    "transformer.h.0.mlp.c_fc.bias",
    "transformer.h.8.attn.c_proj.bias",
    "transformer.h.11.attn.c_proj.bias",
    "transformer.h.3.ln_1.weight",
    "transformer.h.5.ln_2.weight",
    "transformer.h.6.ln_2.weight",
    "transformer.h.9.ln_2.weight",
    "transformer.h.0.ln_2.weight",
    "transformer.h.1.attn.c_attn.bias",
    "transformer.h.8.mlp.c_fc.bias",
    "transformer.h.1.ln_2.weight",
    "transformer.h.10.attn.c_attn.bias",
    "transformer.h.3.attn.c_proj.bias",
    "transformer.h.5.attn.c_attn.bias",
    "transformer.h.8.ln_1.weight",
    "transformer.ln_f.weight",
    "transformer.h.1.mlp.c_proj.bias",
    "transformer.h.0.ln_2.bias",
    "transformer.h.4.attn.c_proj.bias",
    "transformer.h.7.mlp.c_fc.bias",
    "transformer.h.3.mlp.c_fc.bias",
    "transformer.h.5.mlp.c_fc.bias",
    "transformer.h.3.mlp.c_proj.bias",
    "transformer.h.3.ln_2.weight",
    "transformer.h.1.ln_1.weight",
    "transformer.h.5.ln_1.bias",
    "transformer.h.2.ln_1.weight",
    "transformer.h.7.ln_2.bias",
    "transformer.h.10.ln_1.bias",
    "transformer.h.2.attn.c_proj.bias",
    "transformer.wte.weight",
    "transformer.h.2.mlp.c_proj.bias",
    "transformer.h.0.ln_1.bias",
    "transformer.h.9.attn.c_attn.bias",
    "transformer.h.11.mlp.c_proj.bias",
    "transformer.h.2.attn.c_attn.bias",
    "transformer.h.4.ln_1.bias",
    "transformer.h.5.mlp.c_proj.bias",
    "transformer.h.7.ln_2.weight",
    "transformer.h.8.mlp.c_proj.bias",
    "transformer.h.1.attn.c_proj.bias",
    "transformer.h.9.mlp.c_fc.bias",
    "transformer.h.3.ln_1.bias",
    "transformer.h.1.ln_2.bias",
    "transformer.h.2.ln_2.bias",
    "transformer.h.11.ln_2.bias",
    "transformer.h.4.ln_1.weight",
    "transformer.wpe.weight",
]

out = [name for name in requires_grad if name not in all_names]

print(all_names)
artifacts.generate_artifacts(
    model,
    requires_grad=all_names_prev,
    frozen_params=[],
    loss=artifacts.LossType.CrossEntropyLoss,
    optimizer=artifacts.OptimType.AdamW,
    artifact_directory="./artifacts/",
)
